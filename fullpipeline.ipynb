{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:24:02.128543Z",
     "start_time": "2024-05-15T02:24:01.454563Z"
    }
   },
   "source": [
    "import tqdm\n",
    "from diffusers import DiffusionPipeline,RePaintScheduler,RePaintPipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from math import ceil\n",
    "import shutil\n",
    "# slide window \n",
    "def get_views(panorama_height, panorama_width, window_size=64, stride=32):\n",
    "    num_blocks_height = ceil((panorama_height - window_size) / stride) + 1\n",
    "    num_blocks_width = ceil((panorama_width - window_size) / stride) + 1\n",
    "    views = [[] for _ in range(num_blocks_height)]\n",
    "    for i in range(num_blocks_height):\n",
    "        for j in range(num_blocks_width):\n",
    "            h_start = int(i  * stride)\n",
    "            h_end = h_start + window_size\n",
    "            w_start = int(j  * stride)\n",
    "            w_end = w_start + window_size\n",
    "            views[i].append((h_start, h_end, w_start, w_end))\n",
    "    return views\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "12e676db63aa672d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:24:17.773013Z",
     "start_time": "2024-05-15T02:24:17.735379Z"
    }
   },
   "source": [
    "# layoutdir = 'layout_80-77-24'\n",
    "layoutdir = 'samplelayouts/largeroom_233-270-24'\n",
    "expname = layoutdir.split('/')[-1]\n",
    "outputdir = os.path.join('output',expname)\n",
    "os.makedirs(outputdir, exist_ok=True)\n",
    "shutil.copytree(layoutdir, os.path.join(outputdir,'layout_'+ layoutdir.split('/')[-1].split('_')[1] ))\n",
    "x,z,stride = layoutdir.split('_')[1].split('-')\n",
    "x,z,stride = int(x),int(z),int(stride)\n",
    "y = 32 #fixed\n",
    "target_vol_shape = (x,y,z)\n",
    "views = get_views(x, z,window_size=32,stride=stride)\n",
    "num_views = len(views)*len(views[0])\n",
    "\n",
    "layoutlatent = np.zeros((num_views,9,32,96),dtype=np.float32)\n",
    "for i in range(len(views)):\n",
    "    for j in range(len(views[0])):\n",
    "        layoutlatent[i * len(views[0]) + j,:,:,32:64]  = np.load(os.path.join(layoutdir,'{}_{}.npy'.format(i,j))).astype(np.float32)\n",
    "\n",
    "# devide slide window\n",
    "# prepare layout\n",
    "in_channel = 2\n",
    "num_inference_steps = 1000"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9e9f04d96065adf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:07:36.890744Z",
     "start_time": "2024-05-14T12:07:35.971604Z"
    }
   },
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\"checkpoints/conditioned\", torch_dtype=torch.float32)\n",
    "pipeline.to(\"cuda\")\n",
    "device = 'cuda'\n",
    "generator = torch.Generator(device=pipeline.device).manual_seed(99)\n",
    "for v in pipeline.unet.parameters():\n",
    "    v.requires_grad=False\n",
    "image_shape = (num_views, in_channel, *pipeline.unet.config.sample_size)\n",
    "images = randn_tensor(image_shape, generator=generator, device=pipeline.device)\n",
    "layoutlatent = torch.from_numpy(layoutlatent).to(pipeline.device)\n",
    "# prepare noise"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae1d015a30404ac58cd6b42eb959e244"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "7b63ae0a33fe9eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:18:22.608995Z",
     "start_time": "2024-05-14T12:07:36.892231Z"
    }
   },
   "source": [
    "pipeline.scheduler.set_timesteps(num_inference_steps)\n",
    "with torch.autocast('cuda'):\n",
    "    for t in tqdm.tqdm(pipeline.scheduler.timesteps):\n",
    "        images = torch.cat((images, layoutlatent), dim=1)\n",
    "        model_output = pipeline.unet(images, t).sample\n",
    "        images = pipeline.scheduler.step(model_output, t, images[:,:in_channel,:,:], generator=generator).prev_sample\n",
    "images = images*1.42\n",
    "# infer without considering adjacency relevance"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [10:45<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "ab77ed080937a746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T12:18:22.616119Z",
     "start_time": "2024-05-14T12:18:22.609888Z"
    }
   },
   "source": [
    "x = 32 + (len(views)-1)*stride\n",
    "z = 32 + (len(views[0])-1)*stride\n",
    "latent1 = torch.randn((len(views[0]), in_channel, x, y), device=device)\n",
    "latent2 = torch.randn((1, in_channel, x, z), device=device)\n",
    "latent3 = torch.randn((len(views), in_channel, z, y), device=device)\n",
    "noise = torch.randn((num_views, in_channel, 32, 96), device=device)\n",
    "\n",
    "original_image = torch.zeros_like(noise)\n",
    "mask_image = torch.zeros_like(noise)\n",
    "\n",
    "for i in range(len(views)):\n",
    "    for j in range(len(views[0])):\n",
    "        if i % 2 == 0 and j % 2 == 0:\n",
    "            original_image[i * len(views[0]) + j, :, :, :] = images[i * len(views[0]) + j]\n",
    "            mask_image[i*len(views[0])+j, :, :, :] = 1\n",
    "\n",
    "# load latent at intervals"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "581da8883502f497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:35:58.241851Z",
     "start_time": "2024-05-14T12:18:22.617069Z"
    }
   },
   "source": [
    "del pipeline,images\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "generator = torch.Generator(device='cuda').manual_seed(7)\n",
    "scheduler = RePaintScheduler.from_pretrained(\"checkpoints/conditioned/scheduler\")\n",
    "pipeline = RePaintPipeline.from_pretrained(\"checkpoints/conditioned\", scheduler=scheduler)\n",
    "for v in pipeline.unet.parameters():\n",
    "    v.requires_grad=False\n",
    "device = \"cuda\"\n",
    "pipeline = pipeline.to(device)\n",
    "weight = 1000000 #very large number, make it easy to do repaint \n",
    "\n",
    "count1 = torch.zeros_like(latent1)\n",
    "value1 = torch.zeros_like(latent1)\n",
    "count2 = torch.zeros_like(latent2)\n",
    "value2 = torch.zeros_like(latent2)\n",
    "count3 = torch.zeros_like(latent3)\n",
    "value3 = torch.zeros_like(latent3)\n",
    "\n",
    "\n",
    "num_inference_steps=1000\n",
    "jump_length=100 # steps of resample\n",
    "jump_n_sample=8 # times of resample\n",
    "generator=generator\n",
    "scheduler.set_timesteps(num_inference_steps, jump_length, jump_n_sample, device)\n",
    "t_last = scheduler.timesteps[0] + 1\n",
    "\n",
    "with torch.autocast('cuda'):\n",
    "    for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "        if t < t_last:\n",
    "            noise = torch.cat((noise,layoutlatent),dim=1)\n",
    "            count1.zero_()\n",
    "            value1.zero_()\n",
    "            count2.zero_()\n",
    "            value2.zero_()\n",
    "            count3.zero_()\n",
    "            value3.zero_()\n",
    "            latent1.zero_()\n",
    "            latent2.zero_()\n",
    "            latent3.zero_()\n",
    "            model_output = pipeline.unet(noise, t).sample\n",
    "            noise = scheduler.step(model_output, t, noise[:,:in_channel,:,:], original_image, mask_image, generator).prev_sample\n",
    "            for i in range(len(views)):\n",
    "                for j in range(len(views[0])):\n",
    "                    if i%2==0 and j%2==0:\n",
    "                        x_start, x_end, z_start, z_end = views[i][j]\n",
    "                        noise1, noise2, noise3 = noise[i * len(views[0]) + j].split(32, dim=-1)\n",
    "                        value1[j, :, x_start:x_end, :] += weight*noise1\n",
    "                        count1[j, :, x_start:x_end, :] += weight\n",
    "                        value2[:, :, x_start:x_end, z_start:z_end] += weight*noise2\n",
    "                        count2[:, :, x_start:x_end, z_start:z_end] += weight\n",
    "                        value3[i, :, z_start:z_end, :] += weight*noise3\n",
    "                        count3[i, :, z_start:z_end, :] += weight\n",
    "                    else:\n",
    "                        x_start, x_end, z_start, z_end = views[i][j]\n",
    "                        noise1, noise2, noise3 = noise[i * len(views[0]) + j].split(32, dim=-1)\n",
    "                        value1[j, :, x_start:x_end, :] += noise1\n",
    "                        count1[j, :, x_start:x_end, :] += 1\n",
    "                        value2[:, :, x_start:x_end, z_start:z_end] += noise2\n",
    "                        count2[:, :, x_start:x_end, z_start:z_end] += 1\n",
    "                        value3[i, :, z_start:z_end, :] += noise3\n",
    "                        count3[i, :, z_start:z_end, :] += 1\n",
    "            latent1 = torch.where(count1 > 0, value1 / count1, value1)\n",
    "            latent2 = torch.where(count2 > 0, value2 / count2, value2)\n",
    "            latent3 = torch.where(count3 > 0, value3 / count3, value3)\n",
    "            for i in range(len(views)):\n",
    "                for j in range(len(views[0])):\n",
    "                    x_start, x_end, z_start, z_end = views[i][j]\n",
    "                    noise[i*len(views[0])+j, :, :, :32] = latent1[j,:,x_start:x_end, :]\n",
    "                    noise[i*len(views[0])+j, :, :,32:64] = latent2[:,:,x_start:x_end, z_start:z_end]\n",
    "                    noise[i*len(views[0])+j, :, :,64:] = latent3[i,:,z_start:z_end,:]\n",
    "        else:\n",
    "            noise = scheduler.undo_step(noise, t_last, generator)\n",
    "        t_last = t\n",
    "#"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45138ef1bcfa467c8d48f81689fe6f26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13600/13600 [1:17:34<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ed77ac40376b0e76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:35:58.254844Z",
     "start_time": "2024-05-14T13:35:58.242886Z"
    }
   },
   "source": [
    "images = noise.cpu().numpy()\n",
    "images = images*1.42\n",
    "latent_dir = os.path.join(outputdir,'latents')\n",
    "os.makedirs(latent_dir,exist_ok=True)\n",
    "for i in range(len(views)):\n",
    "    for j in range(len(views[0])):\n",
    "        image = images[i*len(views[0])+j]\n",
    "        np.save(os.path.join(latent_dir,str(i)+'_'+str(j)+'.npy'),image[np.newaxis,:])\n",
    "# save"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "118d0000154adda7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:24:23.444356Z",
     "start_time": "2024-05-15T02:24:23.426306Z"
    }
   },
   "source": [
    "from decode import test_vae_sdf\n",
    "\n",
    "meshdir = os.path.join(outputdir,'mesh')\n",
    "os.makedirs(meshdir ,exist_ok=True)\n",
    "test_vae_sdf(latent_dir,meshdir)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m meshdir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(outputdir,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmesh\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(meshdir ,exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 5\u001B[0m test_vae_sdf(\u001B[43mlatent_dir\u001B[49m,meshdir)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'latent_dir' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c4a533efe2a7fda9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:14:27.126240Z",
     "start_time": "2024-05-15T02:14:27.101459Z"
    }
   },
   "source": [
    "from postprocess import postprocess\n",
    "for i in range(len(views)):\n",
    "    for j in range(len(views[0])):\n",
    "        t  = np.load(os.path.join(layoutdir,'{}_{}.npy'.format(i,j))).astype(np.float32)\n",
    "        if t.max() == 0:\n",
    "            os.remove(os.path.join(meshdir,'{}_{}.ply'.format(i,j)))\n",
    "\n",
    "postprocess(outputdir)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/largeroom_233-270-24/mesh/0_5.ply'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m         t  \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(layoutdir,\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i,j)))\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m----> 6\u001B[0m             \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremove\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeshdir\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m.ply\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43mj\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m postprocess(outputdir)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'output/largeroom_233-270-24/mesh/0_5.ply'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d01ac962-5222-4cbc-98e4-e6f87fc06c1c",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
